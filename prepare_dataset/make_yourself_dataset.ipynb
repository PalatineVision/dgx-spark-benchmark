{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-19T22:11:32.574374Z",
     "start_time": "2025-12-19T22:11:32.572270Z"
    }
   },
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from random import choice\n",
    "\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer"
   ],
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T21:48:38.329868Z",
     "start_time": "2025-12-19T21:48:36.737710Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# т.к. будем тестировать модели серии Qwen возьмём токенизатор этой модели, для подсчёта длины контекста\n",
    "# может понадобиться VP* для загрузки конфига токенизатора\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen3-0.6B\")"
   ],
   "id": "5b090732a984c6de",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T21:48:43.027492Z",
     "start_time": "2025-12-19T21:48:38.917729Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# neural-bridge/rag-dataset-12000\n",
    "splits = {'train': 'data/train-00000-of-00001-9df3a936e1f63191.parquet', 'test': 'data/test-00000-of-00001-af2a9f454ad1b8a3.parquet'}\n",
    "rag_df = pd.read_parquet(\"hf://datasets/neural-bridge/rag-dataset-12000/\" + splits[\"train\"])"
   ],
   "id": "31910dd27c1881a5",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T21:58:36.945872Z",
     "start_time": "2025-12-19T21:57:24.000618Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# расширим контекст для тестов с длинным контекстом\n",
    "rag_df[\"long_context\"] = rag_df[\"context\"].apply(lambda x: x * 10)\n",
    "\n",
    "# Считаем посимвольную длину каждого поля\n",
    "rag_df[\"len_context\"] = rag_df[\"context\"].apply(lambda x: len(tokenizer.tokenize(x)) if x is not None else 0)\n",
    "rag_df[\"len_long_context\"] = rag_df[\"long_context\"].apply(lambda x: len(tokenizer.tokenize(x)) if x is not None else 0)\n",
    "rag_df[\"len_question\"] = rag_df[\"question\"].apply(lambda x: len(tokenizer.tokenize(x)) if x is not None else 0)\n",
    "rag_df[\"len_answer\"] = rag_df[\"answer\"].apply(lambda x: len(tokenizer.tokenize(x)) if x is not None else 0)"
   ],
   "id": "3e655cc0fbb8f4b0",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T22:07:09.216486Z",
     "start_time": "2025-12-19T22:07:09.211116Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Выбираем данные с большим контекстом для RAG бенчмарка\n",
    "long_context_data = rag_df[rag_df[\"len_long_context\"] > 15000]\n",
    "\n",
    "# Выбираем данные с большим контекстом для RAG бенчмарка\n",
    "middle_context_data = rag_df[rag_df[\"len_context\"].between(1000, 4000)]\n",
    "\n",
    "# Выбираем данные с небольшим контекстом для Chat бенчмарка\n",
    "chat_data = rag_df[rag_df[\"len_question\"].between(30, 70)]"
   ],
   "id": "d0ee93ff3db4a8c8",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T22:09:00.857393Z",
     "start_time": "2025-12-19T22:09:00.849494Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Выбираем сэмплы из каждого датасета\n",
    "long_rag_selected = long_context_data.index.to_list()\n",
    "middle_rag_selected = []\n",
    "chat_selected = []\n",
    "\n",
    "for _ in list(range(50)):\n",
    "    middle_rag_selected.append(choice(list(middle_context_data.index)))\n",
    "\n",
    "for _ in list(range(50)):\n",
    "    chat_selected.append(choice(list(chat_data.index)))\n",
    "\n",
    "print(\"=\"*15, f\"RAG long context ({len(long_rag_selected)} items)\", \"=\"*15)\n",
    "print(long_context_data.index.to_list())\n",
    "print(\"=\"*15, f\"RAG middle context ({len(middle_rag_selected)} items)\", \"=\"*15)\n",
    "print(middle_rag_selected)\n",
    "print(\"=\"*15, f\"Chat data ({len(chat_selected)} items)\", \"=\"*15)\n",
    "print(chat_selected)"
   ],
   "id": "8e55c9f58e6f66b3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============== RAG long context (28 items) ===============\n",
      "[247, 828, 862, 1152, 1326, 1851, 2222, 2526, 2934, 2953, 3193, 3241, 3607, 3775, 4001, 4138, 4637, 6010, 6256, 6523, 7302, 7410, 7449, 7612, 7952, 8435, 8619, 8890]\n",
      "=============== RAG middle context (50 items) ===============\n",
      "[8364, 7171, 4257, 7454, 6888, 3550, 9557, 7586, 1628, 7280, 4010, 7076, 114, 7213, 4105, 6185, 2939, 8002, 8341, 6863, 301, 5523, 3191, 6413, 7006, 2076, 2447, 1021, 680, 6945, 936, 8111, 4798, 671, 7915, 6965, 231, 1330, 8528, 6150, 4978, 2750, 2122, 4761, 5420, 7075, 5499, 534, 8784, 3173]\n",
      "=============== Chat data (50 items) ===============\n",
      "[3452, 828, 7498, 4425, 2712, 4337, 5683, 5345, 1837, 1793, 4636, 2784, 5683, 2154, 8110, 2276, 6718, 6056, 4618, 8732, 1929, 4875, 2197, 4363, 6561, 8958, 4337, 8655, 4750, 4952, 9533, 69, 9193, 1765, 3904, 7615, 2276, 800, 4932, 1706, 2459, 4346, 1922, 2712, 4242, 5018, 28, 5865, 4223, 9193]\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T22:10:34.569666Z",
     "start_time": "2025-12-19T22:10:34.559634Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# сохраняем данные в формате, пригодном для vLLM бенчмарка\n",
    "\n",
    "dataset_path = Path(\"dataset\")\n",
    "dataset_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(dataset_path / \"long_context_rag.jsonl\", \"w\", encoding=\"utf-8\") as rag_dataset_file:\n",
    "    for idx, raw in rag_df.loc[long_rag_selected].iterrows():\n",
    "        rag_dataset_file.write(\n",
    "            json.dumps({\"prompt\": f\"Context:\\n{raw['context']}\\n\\nUser question:\\n{raw['question']}\\n\"}) + \"\\n\"\n",
    "        )\n",
    "\n",
    "with open(dataset_path / \"middle_context_rag.jsonl\", \"w\", encoding=\"utf-8\") as rag_dataset_file:\n",
    "    for idx, raw in rag_df.loc[middle_rag_selected].iterrows():\n",
    "        rag_dataset_file.write(\n",
    "            json.dumps({\"prompt\": f\"Context:\\n{raw['context']}\\n\\nUser question:\\n{raw['question']}\\n\"}) + \"\\n\"\n",
    "        )\n",
    "\n",
    "with open(dataset_path.absolute() / \"low_context_chat.jsonl\", \"w\", encoding=\"utf-8\") as chat_dataset_file:\n",
    "    for idx, raw in rag_df.loc[chat_selected].iterrows():\n",
    "        chat_dataset_file.write(\n",
    "            json.dumps({\"prompt\": f\"{raw['question']}\"}) + \"\\n\"\n",
    "        )"
   ],
   "id": "d7ff9cf3a02ff221",
   "outputs": [],
   "execution_count": 33
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
